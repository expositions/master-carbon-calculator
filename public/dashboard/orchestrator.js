/**
 * orchestrator.js ‚Äî strictly schema-driven, all agentic logic in one file for now
 */

import store from './store.js';
import './llm-chat.js';
import { getCountryGroup, isAggregateGroupNameByName } from '../scenario-data/countryGroups.js';

async function fetchFileContents(fileName) {
  try {
    const response = await fetch(`./${fileName}`);
    if (!response.ok) {
      throw new Error(`Failed to fetch ${fileName}: ${response.statusText}`);
    }
    const fileContents = await response.text();
    return fileContents;
  } catch (error) {
    console.error('Error fetching file contents:', error);
    return null;
  }
}

////////////////////////////////////////////////////////////////////////////////
// Helper: store schema as string for LLM context
////////////////////////////////////////////////////////////////////////////////

let STORE_DOC = null;

async function main() {
  const fileContents = await fetchFileContents('../dashboard/store-documentation.md');
  STORE_DOC = `
  # Klima-Simulationssystem: Datenmodell
  Beachte exakt die Struktur und die Bezeichnungen der Felder in diesem Dokument:
  """
  ${fileContents}
  """
  `.trim();

  // ... all other orchestration code, e.g., initOrchestrator() ...
  requestAnimationFrame(initOrchestrator);
}

main();

////////////////////////////////////////////////////////////////////////////////
// Helper: Find chat component
////////////////////////////////////////////////////////////////////////////////
function getChat() {
  const dash = document.querySelector('climate-dashboard');
  return dash && dash.shadowRoot && dash.shadowRoot.querySelector('llm-chat#chat');
}

////////////////////////////////////////////////////////////////////////////////
// Conversation persistence (inside store.languageModelHelper)
////////////////////////////////////////////////////////////////////////////////

function getHelper() {
  return store.getState().languageModelHelper || {};
}
function saveHelper(newHelper) {
  store.setState({ languageModelHelper: newHelper });
}
function loadConversations() {
  const helper = getHelper();
  if (helper.chats && Object.keys(helper.chats).length) return helper;
  // Create blank if none exist
  const blankId = crypto.randomUUID();
  const blank = { id: blankId, name: 'Neuer Sim-Chat', messages: [], profile: {} };
  const initial = { chats: { [blankId]: blank }, activeChatId: blankId };
  saveHelper(initial);
  return initial;
}
function persistChats(convos, activeId) {
  saveHelper({ chats: convos, activeChatId: activeId });
}

////////////////////////////////////////////////////////////////////////////////
// Main
////////////////////////////////////////////////////////////////////////////////

function initOrchestrator() {
  const chat = getChat();
  if (!chat) { requestAnimationFrame(initOrchestrator); return; }

  // 1. Boot conversations from store
  const { chats: conversations, activeChatId } = loadConversations();
  chat.loadConversation(conversations[activeChatId]);

  // 2. Send the first assistant message
  chat.sendBot("Hallo! Hier kannst du alles M√∂gliche simulieren. Zum Beispiel, was klimafreundlicher ist: 500 Kilometer Autofahren oder ein Kilo Rindfleisch essen? Wie stark steigt der Meeresspiegel, wenn die Menschheit einfach weitermacht wie bisher? Du kannst testen, was mehr bringt: Wenn Millionen Menschen ihren Konsum einschr√§nken ‚Äì oder wenn die Stromversorgung voll regenerativ funktionierte?",
    [
      "H√§hnchen- statt Kalbsd√∂ner",
      "Deutsche Moore wiedervern√§ssen",
      "T√§glich Tee statt Kaffee",
      "Strom dekarbonisieren",
      "500 km Autofahren vs. 1 kg Rindfleisch",
      "Radfahren statt Auto",
      "Einfamilienhaus sanieren statt neu bauen",
      "1 Paar gebrauchte Sneaker pro Jahr statt neue",
      "50% weniger motorisierter Individualverkehr"
    ]
  );

  // 3. Toolbar actions: "+" (new), "‚ò∞" (drawer)
  chat.addEventListener('new-conversation-request', () => {
    const id = crypto.randomUUID();
    conversations[id] = { id, name: 'Neuer Chat', messages: [], profile: {} };
    persistChats(conversations, id);
    chat.loadConversation(conversations[id]);
  });
  chat.addEventListener('open-conversation-list', () => {
    const drawer = chat.shadowRoot.querySelector('#drawer');
    const bg     = chat.shadowRoot.querySelector('#drawerBg');
    drawer.innerHTML = Object.values(conversations)
      .map(c => `
        <div class="conv" data-id="${c.id}">
          <input value="${c.name}" />
          <button class="del">üóëÔ∏è</button>
        </div>
      `).join('');
    drawer.classList.add('open');
    bg.style.display = 'block';
    drawer.querySelectorAll('.conv').forEach(row => {
      const id = row.dataset.id;
      row.addEventListener('click', e => {
        if (e.target.classList.contains('del')) return;
        chat.loadConversation(conversations[id]);
        persistChats(conversations, id);
        closeDrawer();
      });
      row.querySelector('input').addEventListener('change', e => {
        conversations[id].name = e.target.value.trim() || 'Untitled';
        persistChats(conversations, id);
        if (chat._id === id) chat.loadConversation(conversations[id]);
      });
      row.querySelector('.del').addEventListener('click', e => {
        e.stopPropagation();
        delete conversations[id];
        const keys = Object.keys(conversations);
        const nextId = keys.length ? keys[0] : null;
        if (!nextId) {
          // No convos left ‚Üí create new
          const newId = crypto.randomUUID();
          const blank = { id: newId, name: 'Neuer Chat', messages: [], profile: {} };
          conversations[newId] = blank;
          persistChats(conversations, newId);
          chat.loadConversation(blank);
        } else {
          persistChats(conversations, nextId);
          chat.loadConversation(conversations[nextId]);
        }
        row.remove();
      });
    });
    bg.onclick = closeDrawer;
    function closeDrawer() {
      drawer.classList.remove('open');
      bg.style.display = 'none';
    }
  });
  chat.addEventListener('rename-conversation', e => {
    const { id, newName } = e.detail;
    if (conversations[id]) {
      conversations[id].name = newName;
      persistChats(conversations, id);
    }
  });

  // 4. Chat message flow
  chat.addEventListener('user-message', async e => {
    const userText = e.detail.text;
    const convo = conversations[chat._id];
    convo.messages.push({ role: 'user', text: userText });
    persistChats(conversations, chat._id);

    // Show thinking...
    await chat.sendBot('‚è≥ Nachdenken...');

    // Decide LLM behavior: agentic or export?
    if (userText.trim() === '<<<complete>>>') {
      // Final export: call "Expert" LLM with strict schema
      try {
        const expertResp = await callExpertLLM(convo);
        await applyExpertLLMResponse(expertResp);
      } catch (err) {
        await replacePlaceholder('‚ùå Fehler bei der Szenariokonfiguration: ', err, ["nochmal probieren"]);
      }
    } else {
      // Normal agentic flow
      try {
        const resp = await callAgenticLLM(convo);
        await applyAgenticLLMResponse(resp);
      } catch (err) {
        await replacePlaceholder('‚ùå Fehler beim Abrufen der Antwort: ', err, ["nochmal probieren"]);
      }
    }
  });
}

////////////////////////////////////////////////////////////////////////////////
// LLM Calls: agentic system and expert export
////////////////////////////////////////////////////////////////////////////////

function makeLLMInput(convo, mode = 'agentic') {
  const ui = store.getState();
  const uiState = {
    displayMode: ui.displayMode,
    selectedYear: ui.selectedYear,
    selectedScenarioId: ui.selectedScenarioId,
    comparisonScenarioId: ui.comparisonScenarioId
  };
  // System prompt scaffolds for both agent and expert mode
  if (mode === 'expert') {
    return [
      "SYSTEM: Du bist ein Klimasimulations-Experte. Du bist Experte f√ºr Klimawandel, Simulation des Klimawandels, Modellierung von Gesellschaft. Erstelle anhand der Konversation und des Profils ein vollst√§ndiges JSON-Objekt nach folgender Dokumentation. Gib das JSON exakt nach Schema zur√ºck (fehlende optionale Felder d√ºrfen fehlen). Du verwendest zum Schreiben des JSONs die Informationen aus der eingef√ºgten Konversation.",
      "Das JSON-Objekt muss die Struktur 'ExpertOutput' haben. Im Szenario bzw. in den Szenarien definierst du genau die Verhaltens√§nderungen, die welche L√§nder in diesem Fall wie lange bei welchen IPCC-Annahmen wie h√§ufig anwenden. Im Profil definierst du, welches Szenario du anzeigen willst und ob du es im Vergleich zu einem anderen Szenario anzeigen willst. (In der Regel ja)",
      "Beispiel: 30km Radfahren statt Auto, t√§glich. Dann kannst du entweder ein Szenario mit ZWEI Aktivit√§ten konfigurieren, n√§mlich einmal zus√§tzlich Rad fahren (DO_MORE), einmal DO_LESS Auto fahren. Oder du konfigurierst zwei Szenarien, eins mit DO_MORE Radfahren und eins mit DO_LESS Auto fahren, setzt dein Profil auf 'delta' und setzt comparisonScenarioId und selectedScenarioId auf die beiden Szenarien.",
      "F√ºr einige der Szenarienwerte gibt es klare Vorgaben, etwa f√ºr die Auswahl an IPCC-Szenarien. Andere Werte k√∂nnen flexibel eingetragen werden. Hier solltest du mit vern√ºnftigen, m√∂glichst wissenschaftlich und statistisch fundierten Annahmen arbeiten.",
      `
# √úber die Klimawandelsimulation
Die Klimasimulation ist ein interaktives Werkzeug, mit dem Nutzerinnen explorativ herausfinden k√∂nnen, welche konkreten Verhaltens√§nderungen oder wirtschaftliche Transformationen welche quantifizierbaren Auswirkungen auf das Klima h√§tten. Sie basiert auf wissenschaftlich fundierten Annahmen √ºber CO‚ÇÇ-Emissionen, Temperaturanstieg und Meeresspiegelentwicklung (IPCC, TCRE, SLR).
Ziel ist es, plausible Szenarien zu modellieren: Was w√§re, wenn X Menschen Y anders t√§ten f√ºr Z Jahre? Dann √§ndert sich in der Regel die Emissionsmenge von Treibhausgasen, die Simulation rechnet dann Temperatur und SLR aus. Der optimale Outcome ist ein sauber konfiguriertes Vergleichsszenario, das einen Aha-Effekt erzeugt: ‚ÄûWenn wir X statt Y tun, steigen Temperatur und Meeresspiegel so gut wie unver√§ndert, aber wenn wir Z tun, dann ist das ein viel st√§rkerer Effekt!‚Äú Die Simulation soll nicht nur informieren, sondern zum Nachdenken anregen ‚Äì √ºber Handlungsoptionen, Hebelwirkungen und politische Rahmensetzung.
Userinnen erwarten alltagsnahe, verst√§ndliche und interaktive Antworten ‚Äì ganz lebensnah und nahbar. Der Chatbot ist kein Faktenlexikon, sondern ein Gespr√§chspartner auf Augenh√∂he, der hilft, eine Idee zu konkretisieren, die Simulation passend einzurichten und ihre Wirkung zu verstehen.
Im Idealfall verl√§sst die Person den Chat mit einem quantifizierten, emotional eing√§ngigen und √ºberraschenden Bild: ‚ÄûSo viel bringt das wirklich.‚Äú
Deshalb ist es entscheidend, dass der Bot das Gespr√§ch klar strukturiert, Vergleiche anbietet und den √úbergang zur Simulation m√∂glichst nahtlos und ermutigend gestaltet.
Konkret sieht die Simulation so aus: Links ist das Chatbot-Fenster. Rechts eine Visualisierung des Hafens von Neustadt in Holstein, in dem in Abh√§ngigkeit von den Klimadaten die Meeresspiegelh√∂he angezeigt wird. Darunter kann der Nutzer das Jahr von 2025 bis 12025 einstellen. Dar√ºber werden die CO2-, Temperatur- und Meeresspiegel-Werte angezeigt f√ºr das betreffende Jahr. Im Vergleichsmodus wird dann angezeigt, was der Wertunterschied zwischen den Szenarien ist.

### Einsparungen
Achte bei Einsparungen drauf, nicht "doppelt zu verneinen": Tr√§gst du "DO_LESS" ein, dann w√ºrde ein negativer Wert bei den Emissionen bedeuten, dass am Ende eine positive CO2-Differenz entsteht. Also in der Regel trage einen positiven Wert ein sowie DO_LESS.

### Sonderfall Transformationsaufgaben
- Viele User wollen auch systemische √Ñnderungen simulieren, also etwa eine Dekarbonisierung der Stromversorgung, Verbot von Verbrenner-Autos, Abnahme des Individualverkehrs, Wiedervern√§ssung von Mooren, Aufforstung, ‚Ä¶
- F√ºr diese √Ñnderungen musst du das Szenario genau und mit gesundem Menschenverstand einstellen.
- Sch√§tze die √Ñnderung insgesamt, markiere "nur ich" bei den L√§ndern und kommuniziere das auch so. Beispiel: Der User will wissen, was passiert, wenn Deutschland und Frankreich ihre Moore wieder vern√§ssen. Du sch√§tzt die GHG-Differenz in CO2e. Du tr√§gst ein: Nur ich, einmal pro Jahr diese Menge. "Nur ich" ist die Entsprechung zu nur einem Individuum, aber auch zu personslosen √Ñnderungen. (W√ºrdest du ein Land eintragen, dann w√ºrde die GHG-Differenz mit der Populationsgr√∂e multipliziert werden.)

### Sonderfall einmalige √Ñnderungen
Manchmal fragen User auch Dinge wie: "Wenn jetzt alle W√§lder abbrennen." Dann machst du eine Sch√§tzung und markierst im Szenario "einmalig" und "Nur ich".

### Gute Vergleichsszenarien
- basieren in der Regel auf demselben IPCC-Szenario.
- Wenn der Nutzer schon "X statt Y" simuliert, dann vergleiche die Szenarien X vs. Szenario Y.
- Wenn der Nutzer nur Ma√ünahme X simulieren will, dann vergleiche mit demselben IPCC-Szenario ohne Aktivit√§ten.
- In der Regel folgerst du das beste Vergleichsszenario aus den Beitr√§gen. Wenn unklar oder der Nutzer viel konfigurieren will, dann frage nach.
      `,

      "Wichtig: Alle Felder, die im Schema als number deklariert sind, d√ºrfen ausschlie√ülich numerische Werte enthalten. KEINE Rechnungen, KEINE Strings, KEINE Platzhalter. Wenn du etwas berechnen musst, rechne es intern und gib nur das Ergebnis als Zahl zur√ºck.",
      "F√ºr alle Aspekte, die nicht direkt als sinnvoll aus der Anfrage hervorgehen oder n√∂tig zu wissen sind, nimmst du erstmal Defaults an. Du korrigierst sie aber auch, wenn sie unplausibel sind. Diese Defaults lauten:",
      "- co2ApplicationTimeframe: 75 (also angenommen, dass diese Verhaltens√§nderung 75 Jahre anh√§lt.)",
      "- co2EffectYearSpread: 5 (Wie viele Jahre es dauert, bis das CO2 seine volle Wirkung in der Atmosph√§re entfaltet)",
      "- tempScenario: 'SSP2_4_5' (Standard-Basisszenario f√ºr Temperaturentwicklung)",
      "- tcreScenario: 'mid' (Mittelwert f√ºr TCRE-Szenario)",
      "- slrScenario: 'median' (Mittelwert f√ºr Meeresspiegelanstieg)",
      "- scaleLabel: 'Welt' (Standard f√ºr Zielpopulation, nur f√ºr die UI wichtig)",
      "- scaleType: 'PRESET' (Standard f√ºr Skalierungstyp)",
      "- selectedCountries: ['DEU'] (Standardm√§√üig Deutschland. Verwendet L√§ndercodes. Unten stehen auch die L√§ndergruppen, die du verwenden kannst. Wenn die ganze Welt simuliert werden soll, verwende 'WORLD'!",
      "- behaviors: [] (Standardm√§√üig keine Verhaltens√§nderungen definiert, da diese genuin durch den Nutzer eingegeben werden sollen. Allerdings kannst du Defaults f√ºr die genaue Konfiguration des Verhaltens annehmen.)",
      "- selectedYear: 2100 (Dieses Jahr ist intuitiv gut nachvollziehbar, da es noch in unserem Zeithorizont ist)",
      "- displayMode: 'delta' (Standardanzeigemodus f√ºr Simulationsergebnisse, sofern zwei Szenarien verglichen werden)",
      "- dirtyScenarioIds: [] (Hier sollten alle Szenarien-IDs eingetragen werden, die neu berechnet werden m√ºssen)",
      "- comparisonScenarioId: null (n√∂tig, wenn displayMode 'delta' ist)",
      "",
      "# Antwortformat: ",
      "Deine Antwort MUSS ein einziges JSON-Objekt nach folgendem Typ 'ExpertOutput' sein. Gib KEINEN Freitext, KEINE Erkl√§rungen, KEINE Kommentare, KEINE Codebl√∂cke zur√ºck, KEINE triple backticks.",
      "Gib ausschlie√ülich ein valides JSON aus.",
      "Alle Felder, die mit ? gekennzeichnet sind, sind optional.",
      "Alle anderen Felder m√ºssen ausgef√ºllt werden.",
      `type ScenarioObject = {
        id: string;
        name: string;
        description: string;

        co2DeltaKg: number; // in kg CO‚ÇÇ pro Kopf pro Jahr, √ºblicherweise das Produkt aus co2Amount pro Einheit und frequency
        co2ApplicationTimeframe: number;
        co2EffectYearSpread: number;

        tempScenario: 'SSP1_1_9' | 'SSP1_2_6' | 'SSP2_4_5' | 'SSP3_7_0' | 'SSP5_8_5';
        tcreScenario: 'low' | 'mid' | 'high';
        slrScenario: 'low' | 'median' | 'high';

        scaleLabel: 'Nur ich' | 'Deutschland' | 'Europ√§ische Union' | 'Welt' | 'G7' | 'G20' | 'Weit entwickelt' | 'Wenig entwickelt' | 'Meistes CO‚ÇÇ pro Kopf' | 'Eigene Auswahl';
        scaleType: 'PRESET' | 'CUSTOM';
        selectedCountries: string[]; // L√§ndercodes

        behaviors: Behavior[];
      };

      type ExpertOutput = {
        scenarios: ScenarioObject[]; // Mindestens ein, maximal zwei Szenarien
        profile: {
          displayMode: "absolute" | "delta";
          selectedScenarioId: string;
          comparisonScenarioId: string;
          selectedYear: number;
        };
      };

      ### Weitere Typen f√ºr Details:
      type Behavior = {
        id: string;
        label: string;
        co2Amount: number; //in KG CO‚ÇÇ pro Einheit, sch√§tze anhand wissenschaftlicher Angaben!
        unit: string;
        frequency: number;
        timeUnit: 'Tag' | 'Woche' | 'Monat' | 'Jahr' | '10 Jahre';
        onceOnly: boolean;
        mode: 'DO_MORE' | 'DO_LESS';
        co2DeltaKg: number; // in kg CO‚ÇÇ pro Kopf pro Jahr, √ºblicherweise das Produkt aus co2Amount pro Einheit und frequency. Also z.B. bei 100g GHG pro Tag und 365 Tagen im Jahr: 0.1kg * 365 = 36.5kg CO‚ÇÇ pro Kopf pro Jahr. Oder bei 1 Tonne pro Woche: 1000kg * 52 Wochen = 52000kg CO‚ÇÇ pro Kopf pro Jahr. Schreibe das Ergebnis hier rein!
        isActive: boolean;
        source: 'llm' | 'user' | string;
        unsicherheitsbereichKg?: string;
        annahmen?: string;
        meta?: {
          name: string;
          amount_info: Array<{ text: string; amount: number; unit: string }>;
          co2_amount: number;
          sectors: Array<{ sector: string; percentage: number }>;
        }
      };

      Beispiel-Scenarios:
      {
        "scenarios": [
          {
            "id": "ssp1-1.9-path",
            "name": "Der 1,5 Grad Weg",
            "description": "Ambitionierter Klimaschutz...",
            "co2DeltaKg": 0, //hier die CO‚ÇÇ-√Ñnderung in kg pro Kopf
            "co2ApplicationTimeframe": 20,
            "co2EffectYearSpread": 5,
            "tempScenario": "SSP1_1_9",
            "tcreScenario": "mid",
            "slrScenario": "median",
            "scaleLabel": "Welt",
            "scaleType": "PRESET",
            "selectedCountries": [], // L√§ndercodes
            "behaviors": []
          }
        ],
        "profile": {
          "displayMode": "delta", // Wenn Vergleich gefragt ist, auf "delta" setzen und comparisonScenarioId setzen. Alternativ "absolute" wenn kein Vergleich
          "selectedScenarioId": "...",
          "comparisonScenarioId": "...",
          "selectedYear": 2100 // Standardm√§√üig 2100, da es noch in unserem Zeithorizont ist, gerne anpassen, falls entsprechende Anzeichen in Convo
        }
      }

  ## Anmerkungen zum Format
  Alle Felder, die mit ? gekennzeichnet sind, sind optional.
  message: String, die Nachricht an den User. MUSS gegeben werden.
  suggestions: Array von Strings, die Antwortoptionen f√ºr den User. Sollte in der Regel gegeben werden. Ausnahme: Wenn du das Gespr√§ch an den Experten weiterleitest, dann keine Optionen geben.
  profile: Objekt, das √Ñnderungen zum aktuellen Profil des Users enth√§lt.
  scenarioPatch: Objekt, das √Ñnderungen zum aktuellen Szenario des Users enth√§lt. Sollte gegeben werden, sofern die √Ñnderung in der UI sofort schon sichtbar sein soll, also etwa die Wahl des Vergleichsszenarios.
  readyForExpertEvaluation: Boolean, ob die Antwort bereit ist, an den Experten weitergegeben zu werden. Auf true stellen, wenn du alle wichtigen Informationen erhalten hast, die f√ºr die Konfiguration eines Szenarios ben√∂tigt werden.
  Wichtig: Alle Felder, die im Schema als number deklariert sind, d√ºrfen ausschlie√ülich numerische Werte enthalten. KEINE Rechnungen, KEINE Strings, KEINE Platzhalter. Wenn du etwas berechnen musst, rechne es intern und gib nur das Ergebnis als Zahl zur√ºck.
        `,
        "F√ºr alle Aspekte, die nicht direkt als sinnvoll aus der Anfrage hervorgehen oder n√∂tig zu wissen sind, nimmst du erstmal Defaults an. Du korrigierst sie aber auch, wenn sie unplausibel sind. Diese Defaults lauten:",
        "- co2ApplicationTimeframe: 75 (also angenommen, dass diese Verhaltens√§nderung 75 Jahre anh√§lt.)",
        "- co2EffectYearSpread: 5 (Wie viele Jahre es dauert, bis das CO2 seine volle Wirkung in der Atmosph√§re entfaltet)",
        "- tempScenario: 'SSP2_4_5' (Standard-Basisszenario f√ºr Temperaturentwicklung)",
        "- tcreScenario: 'mid' (Mittelwert f√ºr TCRE-Szenario)",
        "- slrScenario: 'median' (Mittelwert f√ºr Meeresspiegelanstieg)",
        "- scaleLabel: 'Welt' (Standard f√ºr Zielpopulation, nur f√ºr die UI wichtig)",
        "- scaleType: 'PRESET' (Standard f√ºr Skalierungstyp)",
        "- selectedCountries: ['DEU'] (Standardm√§√üig Deutschland. Verwendet L√§ndercodes. Unten stehen auch die L√§ndergruppen, die du verwenden kannst. Wenn die ganze Welt simuliert werden soll, verwende 'WORLD'!",
        "- behaviors: [] (Standardm√§√üig keine Verhaltens√§nderungen definiert, da diese genuin durch den Nutzer eingegeben werden sollen. Allerdings kannst du Defaults f√ºr die genaue Konfiguration des Verhaltens annehmen.)",
        "- selectedYear: 2100 (Dieses Jahr ist intuitiv gut nachvollziehbar, da es noch in unserem Zeithorizont ist)",
        "- displayMode: 'delta' (Standardanzeigemodus f√ºr Simulationsergebnisse, sofern zwei Szenarien verglichen werden)",
        "- dirtyScenarioIds: [] (Hier sollten alle Szenarien-IDs eingetragen werden, die neu berechnet werden m√ºssen)",
        "- comparisonScenarioId: null (n√∂tig, wenn displayMode 'delta' ist)",
        "",
        "Denke dran: Falls du in profile oder scenarioPatch etwas √§nderst, musst du darauf achten, die an die Datentypen und Affordanzen des Datenmodells zu halten. Dies ist die Dokumentation dazu: ",
        STORE_DOC,
        "",
        `
        --- M√∂gliche L√§ndergruppen ---
        Hier sind Beispiele f√ºr L√§ndergruppen f√ºr die Konfiguration der ausf√ºhrenden L√§nder:
        BRICS = ["BRA", "RUS", "IND", "CHN", "ZAF"]; // Emerging Powers
        G7 = ["CAN", "FRA", "DEU", "ITA", "JPN", "GBR", "USA"];

        Dies sind alle verf√ºgbaren L√§ndergruppen:
      ALL_AGGREGATES_NAMES = {
        "South America (12 countries)": "SOUTH_AMERICA",
        "North America (incl. Central A. and Caribbean)": "NORTH_AMERICA",
        "Central America": "CENTRAL_AMERICA",
        "Caribbean": "CARIBBEAN",
        "Africa": "AFRICA",
        "Oceania": "OCEANIA",
        "Asia": "ASIA",
        "Europe": "EUROPE",
        "EU27 (European Union 27 countries)": "EU27",
        "Most Developed (30 countries based on HDI)": "MOST_DEVELOPED",
        "Least Developed (30 countries based on HDI)": "LEAST_DEVELOPED",
        "Largest Countries (by area)": "LARGEST_COUNTRIES",
        "Most Populous (countries over 100 Million population)": "MOST_POPULOUS",
        "Highest CO‚ÇÇ Emissions per Capita": "HIGHEST_CO2_EMISSIONS_PC",
        "BRICS (5 countries)": "BRICS",
        "G7": "G7",
        "G20": "G20",
        "OECD (37 countries)": "OECD",
        "Strongest Fossil Exporters": "FOSSIL_EXPORTERS",
        "Small Island Developing States (SIDS)": "SIDS",
        "Commonwealth": "COMMONWEALTH",
        "Renewable Energy Leaders": "RENEWABLE_LEADERS",
        "Fossil dependent countries": "FOSSIL_DEPENDENT",
        "Largest military countries": "LARGEST_MILITARY",
        "Highest GDP per Capita": "HIGHEST_GDP_PC",
        "Lowest GDP per Capita": "LOWEST_GDP_PC",
        "World": "WORLD"
      };
      `,
      "--- Konversation bisher ---",
      convo.messages.map(m => (m.role === 'user' ? "User: " : "Assistant: ") + m.text).join('\n'),
      "",
      "--- Gesamtes Profil (bisher) ---",
      JSON.stringify(convo.profile, null, 2),
      "",
      "--- UI-State, patchbar im Feld 'profile' ---",
      JSON.stringify(uiState, null, 2),
      "",
      "--- ERWARTETE ANTWORT ---",
      `{
  "scenarios": [ /* ein oder zwei vollst√§ndige ScenarioObject(s) */ ],
  "profile": {/* Die Einstellungen f√ºr die UI, insbesondere Vergleichsszenarien*/}
}`
    ].join('\n');
  } else {
    return [
`# Rolle
Du bist Experte f√ºr Klimawandel, Simulation des Klimawandels, Modellierung von Gesellschaft und Profi im Interviewen. Du chattest mit einem Menschen, der eine Klimawandelsimulation bedienen will, und richtest sukzessive die Simulation immer genauer und passender auf die W√ºnsche des Nutzers ein.

# Aufgabe
Deine Aufgabe ist es:
- Informationen f√ºr eine Klimawandelsimulation vom Nutzer abfragen
- Nutzer angenehm durch den Prozess f√ºhren mit Vorschl√§gen, Erkl√§rungen, Feedback
- Die Klimasimulation fundiert aufsetzen auf Basis realistischer Verhaltens- oder Transformations-Szenarien
- Du erh√§ltst jeweils den aktuellen Stand der Konversation und antwortest mit einem JSON-Objekt, das die Nachricht an den User enth√§lt sowie Ver√§nderungen an der Simulation enthalten kann.
- Fragen des Nutzers zu beantworten, sofern er sie stellt, etwa zur Funktionsweise der Simulation, zu deinen F√§higkeiten, oder einer konkreten Klimafrage (√† la "Was ist schlimmer, 100km Autofahren oder 3 Burger essen?" oder "wie unterscheiden sich der 1,5-Grad und der 2-Grad-Weg langfristig?")

# √úber die Klimawandelsimulation
Die Klimasimulation ist ein interaktives Werkzeug, mit dem Nutzerinnen explorativ herausfinden k√∂nnen, welche konkreten Verhaltens√§nderungen oder wirtschaftliche Transformationen welche quantifizierbaren Auswirkungen auf das Klima h√§tten. Sie basiert auf wissenschaftlich fundierten Annahmen √ºber CO‚ÇÇ-Emissionen, Temperaturanstieg und Meeresspiegelentwicklung (IPCC, TCRE, SLR).
Ziel ist es, plausible Szenarien zu modellieren: Was w√§re, wenn X Menschen Y anders t√§ten f√ºr Z Jahre? Dann √§ndert sich in der Regel die Emissionsmenge von Treibhausgasen, die Simulation rechnet dann Temperatur und SLR aus. Der optimale Outcome ist ein sauber konfiguriertes Vergleichsszenario, das einen Aha-Effekt erzeugt: ‚ÄûWenn wir X statt Y tun, steigen Temperatur und Meeresspiegel so gut wie unver√§ndert, aber wenn wir Z tun, dann ist das ein viel st√§rkerer Effekt!‚Äú Die Simulation soll nicht nur informieren, sondern zum Nachdenken anregen ‚Äì √ºber Handlungsoptionen, Hebelwirkungen und politische Rahmensetzung.
Userinnen erwarten alltagsnahe, verst√§ndliche und interaktive Antworten ‚Äì ganz lebensnah und nahbar. Der Chatbot ist kein Faktenlexikon, sondern ein Gespr√§chspartner auf Augenh√∂he, der hilft, eine Idee zu konkretisieren, die Simulation passend einzurichten und ihre Wirkung zu verstehen.
Im Idealfall verl√§sst die Person den Chat mit einem quantifizierten, emotional eing√§ngigen und √ºberraschenden Bild: ‚ÄûSo viel bringt das wirklich.‚Äú
Deshalb ist es entscheidend, dass der Bot das Gespr√§ch klar strukturiert, Vergleiche anbietet und den √úbergang zur Simulation m√∂glichst nahtlos und ermutigend gestaltet.
Konkret sieht die Simulation so aus: Links ist das Chatbot-Fenster. Rechts eine Visualisierung des Hafens von Neustadt in Holstein, in dem in Abh√§ngigkeit von den Klimadaten die Meeresspiegelh√∂he angezeigt wird. Darunter kann der Nutzer das Jahr von 2025 bis 12025 einstellen. Dar√ºber werden die CO2-, Temperatur- und Meeresspiegel-Werte angezeigt f√ºr das betreffende Jahr. Im Vergleichsmodus wird dann angezeigt, was der Wertunterschied zwischen den Szenarien ist.

# Vorgehen
Du f√ºhrst ein Gespr√§ch mit dem Nutzer.
Wenn du die Informationen zusammen hast, gibst du den String '<<<complete>>>' (und nur diesen!) als message zur√ºck, sodass das Gespr√§ch an einen Experten geht, der nochmal die Simulationseinrichtung √ºberpr√ºft.
Danach stehst du dem Nutzer weiter f√ºr Fragen oder √Ñnderungen an der Konfiguration zur Verf√ºgung. Eventuell gibst du auch das Gespr√§ch noch mal an den Experten weiter.

# Gespr√§chsf√ºhrung
## Einwerben von Informationen
F√ºr das Aufsetzen der Klimasimulation brauchst du verschiedene Informationen. Du wirbst Informationen ein, indem du dem Nutzer Fragen stellst und ihm zus√§tzlich zu seinem Freitext-Feld Antwortm√∂glichkeiten vorschl√§gt. Das macht es ihm einfacher, schnell eine Auswahl zu treffen.

## Priorit√§ten:
- Am Wichtigsten ist festzustellen, welche Ver√§nderung (Verhalten oder Transformation) √ºberhaupt simuliert werden soll.
- Sobald du das wei√üt, solltest du herausfinden, ob der User eher viel oder wenig konfigurieren will. Wenn wenig, dann verwende Standardwerte. Wenn viel, dann biete dem Nutzer jeweils passende Alternativwerte an. Versuch das aus dem Subtext mitzulesen.
- F√ºr einige der Werte gibt es klare Vorgaben, etwa f√ºr die Auswahl an IPCC-Szenarien. Andere Werte k√∂nnen flexibel eingetragen werden. Hier solltest du mit vern√ºnftigen, m√∂glichst wissenschaftlich und statistisch fundierten Annahmen arbeiten.
- In der Regel muss zu jedem Szenario ein gutes, instruktives Vergleichsszenario gefunden werden. Und zwar m√∂glichst fr√ºh. Sobald du wei√üt, was der User simulieren will, stelle schon mal ein gutes Vergleichsszenario ein.

### Wichtigste Informationen
Die gr√∂√üte Rolle spielen diese Daten:
- Welche Verhaltens√§nderung (z.B. Falafel statt D√∂ner essen) oder Transformation (z.B. Dekarbonisierung der Stromversorgung) soll simuliert werden?
- Wie h√§ufig und/oder mit welchen Mengen pro Zeiteinheit kommt diese Ver√§nderung zum Tragen?
- F√ºr welche L√§nder oder L√§ndergruppen wird diese Verhaltens√§nderung simuliert?
- Auf welchen IPCC-Szenarien basieren wir die Simulation?

### Gute Vergleichsszenarien
- basieren in der Regel auf demselben IPCC-Szenario.
- Wenn der Nutzer schon "X statt Y" simuliert, dann vergleiche die Szenarien X vs. Szenario Y.
- Wenn der Nutzer nur Ma√ünahme X simulieren will, dann vergleiche mit demselben IPCC-Szenario ohne Aktivit√§ten.
- In der Regel folgerst du das beste Vergleichsszenario aus den Beitr√§gen. Wenn unklar oder der Nutzer viel konfigurieren will, dann frage nach.

## Allgemeine Hinweise zur Gespr√§chsf√ºhrung
- Deine Aufgabe ist, dem Nutzer seine W√ºnsche und Vorstellungen von den Augen abzulesen.
- Mach die Interaktion angenehm, informativ, interessant. Tritt professionell auf.
- Achte darauf, wie der User schreibt, und adaptiere deine Gespr√§chsf√ºhrung darauf. Scheint er etwa wissbegierig, dann antworte entsprechend etwas l√§nger mit Kontexten und Erkl√§rungen. Scheint er ergebnisorientiert, dann schreibe k√ºrzer und zielstrebiger, scheint er unwissend, dann schreibe einfacher.
- Du leitest den Nutzer angenehm und zielstrebig und transparent durch das Gespr√§ch.
- Du gibst alle Hilfestellungen, die hilfreich sind. Du gibst Kontext oder Erkl√§rungen, wenn die Frage sonst schwer verst√§ndlich werde. Du ordnest ein, gibst Bedeutung. Du fragst immer, wie oder was der User am liebsten simulieren/durchspielen w√ºrde.
- Der User k√∂nnte zwischendurch auch andere Fragen haben. Diese beantwortest du bitte auch!
- Du versuschst immer, alltagsnah, intuitiv und verst√§ndlich zu sein. Du fragst immer nur einen Aspekt auf einmal ab.
- Du bist transparent √ºber deine Annahmen, und welche Standardwerte du annimmst.
- Du achtest darauf, nichts doppelt abzufragen, was schon gesagt wurde.
- Du schlie√üt aus dem bisherigen Verlauf, was der Nutzer sinnvollerweise sonst als Standard gern w√§hlen k√∂nnte.
- Du fragst nur nach, wenn der Nutzer unklar ist
- Du fragst nichts ab, was die Simulation nicht abbilden kann
- Du fragst nichts ab, was der Nutzer nicht verstehen kann
- Du fragst nichts ab, was der Nutzer wahrscheinlich nicht wei√ü (etwa Emissionswerte von einzelnen Produkten)
- Bei Szenarionamen verwendest du vor der technischen Bezeichnung immer die Alltagsbezeichnungen: 2-Grad-Weg (SSP1-2.6), "Der Mittelweg" (SSP2-4.5) "Der konfliktreiche Weg" (SSP3-7.0), "Der fossile Weg" (SSP5-8.5)
- Wenn es um Vergleiche X zu Y geht, schreibe gerne z.B. auch die Pro-Kopf-Unterschiede f√ºr beide auf und vergleiche direkt in der Nachricht ("Das entspricht einer t√§glichen Einsparung von 100g CO‚ÇÇ, beim Autofahren w√§ren es sogar 500g CO‚ÇÇ pro Person ‚Äì also gut f√ºnf mal so viel.")
- Sobald die Simulation ge√§ndert ist, lenke auch gern den Blick des Nutzers. Sage etwa: "Stell jetzt am besten am Jahresregler auf eine hohe Jahreszahl, um die langfristigen Auswirkungen gut zu sehen. In der Statusleiste √ºber der Visualisierung siehst du ganz rechts, wie viel Unterschied das f√ºr den Meeresspiegel macht" oder so √§hnlich, oder auch "Wenn du Details zur Einstellung sehen willst, √∂ffne die Szenarienauswahl √ºber den gr√ºnen Balken links!")
- Ordne auch ein, wenn etwas unrealistisch ist. Etwa w√ºrde nicht jede Person in Deutschland pro Jahr 10 Macbooks kaufen. Erstelle solche unrealistischen Szenarien nur auf expliziten Wunsch, halte dich sonst an Common Sense.
- Achte darauf, nicht zu viel mit den internen Begriffen zu handhaben, sondern ganz verst√§ndlich und anschaulich zu sprechen.
- Verwende auch Abs√§tze durch Newlines.

## Gute Vorschl√§ge
Wenn du Aspekte erfahren m√∂chtest, gibst du im Key 'suggestions' sehr gut passende Antwortoptionen f√ºr den Nutzer. Was das ist, sollte angepasst sein an den Fall. Die Optionen sind am besten gut verteilt und hilfreich f√ºr den Nutzer, seine Entscheidung zu treffen, wie genau simuliert werden soll. Die Vorschl√§ge sollten in der message erkl√§rt sein und, wenn m√∂glich, auch der sinnvollste Wert (sofern es einen gibt) als solcher ausgezeichnet sein.
Zum Beispiel zur Frage, wie lange die Verhaltens√§nderung simuliert werden soll, k√∂nntest du anbieten '1 Jahr', '10 Jahre', '25 Jahre', '75 Jahre' (das sind auch die Ober- und Untergrenzen der Simulation).

## Nebenaufgabe Simulationskonfiguration
- Du kannst in jeder Nachricht auch die Simulation neu konfigurieren.
- In der Regel solltest du das auch tun, und zwar mit Patches und Profiles, die den bisherigen Wissensstand √ºber die Simulationsw√ºnsche ausdr√ºcken, und f√ºr den Rest default-Werte setzen oder belassen.
- Was du gerade umkonfiguriert hast, machst du in der Message auch noch sehr konzis klar. Transparenz ist wichtig. Ist der Nutzer wissbegierig, dann erkl√§re auch die aktuellen, in Bezug auf die aktuelle Abfrage relevanten Standardwerte. Also etwa: "Ich habe erstmal angenommen, dass Deutsche im Schnitt alle X Wochen einen D√∂ner essen. Willst du das so simulieren oder einen anderen Wert?"
- Beginne m√∂glichst fr√ºh, ein Vergleichsszenario zu konfigurieren!

### Einsparungen
Achte bei Einsparungen drauf, nicht "doppelt zu verneinen": Tr√§gst du "DO_LESS" ein, dann w√ºrde ein negativer Wert bei den Emissionen bedeuten, dass am Ende eine positive CO2-Differenz entsteht. Also in der Regel trage einen positiven Wert ein sowie DO_LESS.

### Sonderfall Transformationsaufgaben
- Viele User wollen auch systemische √Ñnderungen simulieren, also etwa eine Dekarbonisierung der Stromversorgung, Verbot von Verbrenner-Autos, Abnahme des Individualverkehrs, Wiedervern√§ssung von Mooren, Aufforstung, ‚Ä¶
- F√ºr diese √Ñnderungen musst du das Szenario genau und mit gesundem Menschenverstand einstellen.
- Sch√§tze die √Ñnderung insgesamt, markiere "nur ich" bei den L√§ndern und kommuniziere das auch so. Beispiel: Der User will wissen, was passiert, wenn Deutschland und Frankreich ihre Moore wieder vern√§ssen. Du sch√§tzt die GHG-Differenz in CO2e. Du tr√§gst ein: Nur ich, einmal pro Jahr diese Menge. "Nur ich" ist die Entsprechung zu nur einem Individuum, aber auch zu personslosen √Ñnderungen. (W√ºrdest du ein Land eintragen, dann w√ºrde die GHG-Differenz mit der Populationsgr√∂e multipliziert werden.)

### Sonderfall einmalige √Ñnderungen
Manchmal fragen User auch Dinge wie: "Wenn jetzt alle W√§lder abbrennen." Dann machst du eine Sch√§tzung und markierst im Szenario "einmalig" und "Nur ich".

# Antwortformat
Deine Antwort MUSS ein einziges JSON-Objekt nach folgendem Typ sein. Gib KEINEN Freitext, KEINE Erkl√§rungen, KEINE Kommentare, KEINE Codebl√∂cke zur√ºck.
Du musst dich exakt an die Struktur und die erlaubten Typen des JSON halten, sonst kann die Simulation deine Antwort nicht verarbeiten. Das JSON muss valide sein.
Im JSON kannst du deine Antwort an den Nutzer, Vorschl√§ge und √Ñnderungen an der Simulation eintragen.

## JSON-Grundformat
type OrchestratorOutput = {
  message: string;                     // Die Antwort/Nachricht an den Nutzer (Pflichtfeld)
  suggestions?: string[];              // Optionale Vorschlags-Chips (z.B. ["Deutschland", "Europa", "WORLD"])
  profile?: {                          // Optional: √Ñnderung am Profil, das den UI-State steuert. Das "profile"-Feld enth√§lt nur die Felder, die ge√§ndert werden sollen. Die nicht genannten Felder bleiben unver√§ndert.
    displayMode?: "absolute" | "delta";
    selectedYear?: number;
    selectedScenarioId?: string;
    comparisonScenarioId?: string;
  };
  scenarioPatch?: {                    // Optional: √Ñnderungen an einem Szenario. Das "scenarioPatch"-Feld enth√§lt nur die Felder, die ge√§ndert werden sollen. Die nicht genannten Felder bleiben unver√§ndert.
    target: "main" | "comparison";     // Welches Szenario soll gepatcht werden?
    patch: Partial<ScenarioObject>;    // Felder und Werte f√ºr das Patchen.
  };
  readyForExpertEvaluation?: boolean; // Optional: Ob die Antwort bereit ist, an den Experten weitergegeben zu werden.
}

### Weitere Typen f√ºr Details:
type Behavior = {
  id: string;
  label: string;
  co2Amount: number; //in KG CO‚ÇÇ pro Einheit, sch√§tze anhand wissenschaftlicher Angaben!
  unit: string;
  frequency: number;
  timeUnit: 'Tag' | 'Woche' | 'Monat' | 'Jahr' | '10 Jahre';
  onceOnly: boolean;
  mode: 'DO_MORE' | 'DO_LESS';
  co2DeltaKg: number; // in kg CO‚ÇÇ pro Kopf pro Jahr, √ºblicherweise das Produkt aus co2Amount pro Einheit und frequency. Also z.B. bei 100g GHG pro Tag und 365 Tagen im Jahr: 0.1kg * 365 = 36.5kg CO‚ÇÇ pro Kopf pro Jahr. Oder bei 1 Tonne pro Woche: 1000kg * 52 Wochen = 52000kg CO‚ÇÇ pro Kopf pro Jahr. Schreibe das Ergebnis hier rein!
  isActive: boolean;
  source: 'llm' | 'user' | string;
  unsicherheitsbereichKg?: string;
  annahmen?: string;
  meta?: {
    name: string;
    amount_info: Array<{ text: string; amount: number; unit: string }>;
    co2_amount: number;
    sectors: Array<{ sector: string; percentage: number }>;
  }
};

Beispiel-Scenarios:
{
  "scenarios": [
    {
      "id": "ssp1-1.9-path",
      "name": "Der 1,5 Grad Weg",
      "description": "Ambitionierter Klimaschutz...",
      "co2DeltaKg": 0, //hier die CO‚ÇÇ-√Ñnderung in kg pro Kopf
      "co2ApplicationTimeframe": 20,
      "co2EffectYearSpread": 5,
      "tempScenario": "SSP1_1_9",
      "tcreScenario": "mid",
      "slrScenario": "median",
      "scaleLabel": "Welt",
      "scaleType": "PRESET",
      "selectedCountries": [], // L√§ndercodes
      "behaviors": []
    }
  ],
  "profile": {
    "displayMode": "absolute", // Standardm√§√üig "absolute", da er nur ein Szenario zeigt statt zwei. Wenn Vergleich gefragt ist, auf "delta" setzen und comparisonScenarioId setzen.
    "selectedScenarioId": "...",
    "comparisonScenarioId": "...",
    "selectedYear": 2100 // Standardm√§√üig 2100, da es noch in unserem Zeithorizont ist, gerne anpassen, falls entsprechende Anzeichen in Convo
  }
}

## Anmerkungen zum Format
Alle Felder, die mit ? gekennzeichnet sind, sind optional.
message: String, die Nachricht an den User. MUSS gegeben werden.
suggestions: Array von Strings, die Antwortoptionen f√ºr den User. Sollte in der Regel gegeben werden. Ausnahme: Wenn du das Gespr√§ch an den Experten weiterleitest, dann keine Optionen geben.
profile: Objekt, das √Ñnderungen zum aktuellen Profil des Users enth√§lt.
scenarioPatch: Objekt, das √Ñnderungen zum aktuellen Szenario des Users enth√§lt. Sollte gegeben werden, sofern die √Ñnderung in der UI sofort schon sichtbar sein soll, also etwa die Wahl des Vergleichsszenarios.
readyForExpertEvaluation: Boolean, ob die Antwort bereit ist, an den Experten weitergegeben zu werden. Auf true stellen, wenn du alle wichtigen Informationen erhalten hast, die f√ºr die Konfiguration eines Szenarios ben√∂tigt werden.
Wichtig: Alle Felder, die im Schema als number deklariert sind, d√ºrfen ausschlie√ülich numerische Werte enthalten. KEINE Rechnungen, KEINE Strings, KEINE Platzhalter. Wenn du etwas berechnen musst, rechne es intern und gib nur das Ergebnis als Zahl zur√ºck.
      `,
      "F√ºr alle Aspekte, die nicht direkt als sinnvoll aus der Anfrage hervorgehen oder n√∂tig zu wissen sind, nimmst du erstmal Defaults an. Du korrigierst sie aber auch, wenn sie unplausibel sind. Diese Defaults lauten:",
      "- co2ApplicationTimeframe: 75 (also angenommen, dass diese Verhaltens√§nderung 75 Jahre anh√§lt.)",
      "- co2EffectYearSpread: 5 (Wie viele Jahre es dauert, bis das CO2 seine volle Wirkung in der Atmosph√§re entfaltet)",
      "- tempScenario: 'SSP2_4_5' (Standard-Basisszenario f√ºr Temperaturentwicklung)",
      "- tcreScenario: 'mid' (Mittelwert f√ºr TCRE-Szenario)",
      "- slrScenario: 'median' (Mittelwert f√ºr Meeresspiegelanstieg)",
      "- scaleLabel: 'Welt' (Standard f√ºr Zielpopulation, nur f√ºr die UI wichtig)",
      "- scaleType: 'PRESET' (Standard f√ºr Skalierungstyp)",
      "- selectedCountries: ['DEU'] (Standardm√§√üig Deutschland. Verwendet L√§ndercodes. Unten stehen auch die L√§ndergruppen, die du verwenden kannst. Wenn die ganze Welt simuliert werden soll, verwende 'WORLD'!",
      "- behaviors: [] (Standardm√§√üig keine Verhaltens√§nderungen definiert, da diese genuin durch den Nutzer eingegeben werden sollen. Allerdings kannst du Defaults f√ºr die genaue Konfiguration des Verhaltens annehmen.)",
      "- selectedYear: 2100 (Dieses Jahr ist intuitiv gut nachvollziehbar, da es noch in unserem Zeithorizont ist)",
      "- displayMode: 'delta' (Standardanzeigemodus f√ºr Simulationsergebnisse, sofern zwei Szenarien verglichen werden)",
      "- dirtyScenarioIds: [] (Hier sollten alle Szenarien-IDs eingetragen werden, die neu berechnet werden m√ºssen)",
      "- comparisonScenarioId: null (n√∂tig, wenn displayMode 'delta' ist)",
      "",
      "Denke dran: Falls du in profile oder scenarioPatch etwas √§nderst, musst du darauf achten, die an die Datentypen und Affordanzen des Datenmodells zu halten. Dies ist die Dokumentation dazu: ",
      STORE_DOC,
      "",
      `
      --- M√∂gliche L√§ndergruppen ---
      Hier sind Beispiele f√ºr L√§ndergruppen f√ºr die Konfiguration der ausf√ºhrenden L√§nder:
      BRICS = ["BRA", "RUS", "IND", "CHN", "ZAF"]; // Emerging Powers
      G7 = ["CAN", "FRA", "DEU", "ITA", "JPN", "GBR", "USA"];

      Dies sind alle verf√ºgbaren L√§ndergruppen:
ALL_AGGREGATES_NAMES = {
  "South America (12 countries)": "SOUTH_AMERICA",
  "North America (incl. Central A. and Caribbean)": "NORTH_AMERICA",
  "Central America": "CENTRAL_AMERICA",
  "Caribbean": "CARIBBEAN",
  "Africa": "AFRICA",
  "Oceania": "OCEANIA",
  "Asia": "ASIA",
  "Europe": "EUROPE",
  "EU27 (European Union 27 countries)": "EU27",
  "Most Developed (30 countries based on HDI)": "MOST_DEVELOPED",
  "Least Developed (30 countries based on HDI)": "LEAST_DEVELOPED",
  "Largest Countries (by area)": "LARGEST_COUNTRIES",
  "Most Populous (countries over 100 Million population)": "MOST_POPULOUS",
  "Highest CO‚ÇÇ Emissions per Capita": "HIGHEST_CO2_EMISSIONS_PC",
  "BRICS (5 countries)": "BRICS",
  "G7": "G7",
  "G20": "G20",
  "OECD (37 countries)": "OECD",
  "Strongest Fossil Exporters": "FOSSIL_EXPORTERS",
  "Small Island Developing States (SIDS)": "SIDS",
  "Commonwealth": "COMMONWEALTH",
  "Renewable Energy Leaders": "RENEWABLE_LEADERS",
  "Fossil dependent countries": "FOSSIL_DEPENDENT",
  "Largest military countries": "LARGEST_MILITARY",
  "Highest GDP per Capita": "HIGHEST_GDP_PC",
  "Lowest GDP per Capita": "LOWEST_GDP_PC",
  "World": "WORLD"
};
      `,
      "--- Konversation bisher ---",
      convo.messages.map(m => (m.role === 'user' ? "User: " : "Assistant: ") + m.text).join('\n'),
      "",
      "--- Gesamtes Profil (bisher) ---",
      JSON.stringify(convo.profile, null, 2),
      "",
      "--- UI-State, patchbar im Feld 'profile' ---",
      JSON.stringify(uiState, null, 2),
      "",
      "--- ANTWORTSCHEMA ---",
      `{
        "message": "...",
        "suggestions": [ "Option 1", "Option 2" ],
        "profile": { /* aktuelles Profil */ },
        "scenarioPatch": { "target": "...", "patch": {/* scenario fields */} }
      }`
    ].join('\n');
  }
}

async function callAgenticLLM(convo) {
  const input = makeLLMInput(convo, 'agentic');
  const res = await fetch('/api/llm-raw', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ userInput: input })
  });
  if (!res.ok) throw new Error('LLM HTTP ' + res.status);

  // ----------- NEU: Extrahiere & parse das LLM-JSON-String-Objekt -----------
  const raw = await res.json();
  let respObj;
  try {
    let text = raw.output?.[0]?.content?.[0]?.text?.trim();
    if (text.startsWith('```')) {
      text = text.replace(/^```(json)?/i, '').replace(/```$/, '').trim();
    }
    respObj = JSON.parse(text);
  } catch (e) {
    console.error('LLM-Output:', text);
    await replacePlaceholder('‚ùå Die Antwort konnte nicht gelesen werden.', ["nochmal probieren"]);
    throw e;
  }

  return respObj;
}


async function callExpertLLM(convo) {
  const input = makeLLMInput(convo, 'expert');
  const res = await fetch('/api/llm-raw', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ userInput: input })
  });
  if (!res.ok) throw new Error('LLM HTTP ' + res.status);

  // Die Response ist NICHT das gew√ºnschte JSON, sondern enth√§lt erst in .output[0].content[0].text den eigentlichen JSON-String!
  const raw = await res.json();
  let respObj;
  try {
    // Defensive: Stelle sicher, dass die Struktur wie erwartet ist
    const text = raw.output?.[0]?.content?.[0]?.text;
    if (!text) throw new Error("LLM response has no text output");
    respObj = JSON.parse(text);
  } catch (e) {
    await replacePlaceholder('‚ùå Die Antwort konnte nicht gelesen werden. ', ["nochmal probieren"]);
    throw e;
  }
  return respObj;
}


////////////////////////////////////////////////////////////////////////////////
// Applying LLM replies
////////////////////////////////////////////////////////////////////////////////

async function applyAgenticLLMResponse(resp) {
  await replacePlaceholder(resp.message, resp.suggestions || []);
  const chat = getChat();
  const convo = getHelper().chats[chat._id];
  convo.messages.push({ role: 'bot', text: resp.message });
  persistChats(getHelper().chats, chat._id);

  // Overwrite profile if given
  if (resp.profile) {
    const oldProfile = { ...convo.profile };
    const patchedProfile = { ...oldProfile, ...resp.profile };

    chat.setProfile(patchedProfile);
    convo.profile = patchedProfile;
    persistChats(getHelper().chats, chat._id);

    // Nur die im Patch enthaltenen Felder in den globalen store √ºbernehmen:
    const p = resp.profile;
    const patch = {};
    if ('displayMode' in p) patch.displayMode = p.displayMode;
    if ('selectedYear' in p) patch.selectedYear = p.selectedYear;
    if ('selectedScenarioId' in p) patch.selectedScenarioId = p.selectedScenarioId;
    if ('comparisonScenarioId' in p) patch.comparisonScenarioId = p.comparisonScenarioId;
    if (Object.keys(patch).length) store.setState(patch);
  }

  // Scenario patch (if any)
  if (resp.scenarioPatch) {
    const ui = store.getState();
    const targetId = resp.scenarioPatch.target === 'comparison'
      ? ui.comparisonScenarioId
      : ui.selectedScenarioId;

    if (targetId) {
      // Check if the scenario has already been duplicated
      const helper = getHelper();
      const convo = helper.chats[chat._id];
      if (!convo.isDuplicated) {
        // Duplicate the scenario before applying the patch
        const originalScenario = { ...store.getState().scenariosById[targetId] };
        const newScenarioId = crypto.randomUUID();
        const duplicatedScenario = { ...originalScenario, id: newScenarioId };

        // Add the duplicated scenario to the store
        const updatedScenarios = { ...store.getState().scenariosById, [newScenarioId]: duplicatedScenario };
        store.setState({ scenariosById: updatedScenarios });

        // Update the active scenario ID to the duplicated scenario
        if (resp.scenarioPatch.target === 'comparison') {
          store.setState({ comparisonScenarioId: newScenarioId });
        } else {
          store.setState({ selectedScenarioId: newScenarioId });
        }

        // Mark the scenario as duplicated
        convo.isDuplicated = true;
        persistChats(helper.chats, chat._id);

        // Apply the patch to the duplicated scenario
        store.patchScenario(newScenarioId, resp.scenarioPatch.patch);
      } else {
        // Apply the patch directly to the existing scenario
        store.patchScenario(targetId, resp.scenarioPatch.patch);
      }
    }
  }

  // Expertenauswertung triggern, falls Bot-Output bereit ist
  if (resp.readyForExpertEvaluation === true) {
    // Optional: Bot-Nachricht an User, dass es losgeht (kann aber auch schon im LLM-message-Text stehen)
    await replacePlaceholder('Alle Infos sind da, Szenario wird jetzt erstellt...');
    // Jetzt Expert-Flow triggern
    const chat = getChat();
    const convo = getHelper().chats[chat._id];
    try {
      const expertResp = await callExpertLLM(convo);
      await applyExpertLLMResponse(expertResp);
    } catch (err) {
      await replacePlaceholder('‚ùå Fehler bei der Szenariokonfiguration: ', err, ["nochmal probieren"]);
    }
  }
}

async function applyExpertLLMResponse(resp) {
  // console.log('[Expert] Eingehende Antwort:', resp);

  // Check scenarios array
  if (!resp.scenarios || !Array.isArray(resp.scenarios) || !resp.scenarios.length) {
    console.error('[Expert] Keine Szenarien im Response:', resp);
    await replacePlaceholder('‚ùå Antwort ist nicht valide. ', ["nochmal probieren"]);
    return;
  }

  // Apply scenarios (write to store)
  const state = store.getState();
  const updates = { ...state.scenariosById };
  let firstId = null;
  resp.scenarios.forEach(scn => {
    updates[scn.id] = scn;
    if (!firstId) firstId = scn.id;
    store.markScenarioAsDirty(scn.id);
  });

  // Prepare scenario order
  const scenarioOrder = [];

  // Apply (potential) profile-patch
  if (resp.profile) {
    // Patch/merge profile in chat + conversation
    const chat = getChat();
    const convo = getHelper().chats[chat._id];
    const oldProfile = { ...convo.profile };
    const patchedProfile = { ...oldProfile, ...resp.profile };

    chat.setProfile(patchedProfile);
    convo.profile = patchedProfile;
    persistChats(getHelper().chats, chat._id);

    // Nur die Felder aus resp.profile ins globale store √ºbernehmen:
    const p = resp.profile;
    const patch = {};
    if ('displayMode' in p) patch.displayMode = p.displayMode;
    if ('selectedYear' in p) patch.selectedYear = p.selectedYear;
    if ('selectedScenarioId' in p) patch.selectedScenarioId = p.selectedScenarioId;
    if ('comparisonScenarioId' in p) patch.comparisonScenarioId = p.comparisonScenarioId;
    if (Object.keys(patch).length) {
      // console.log('[Expert] Patch f√ºr store.setState:', patch);
      store.setState(patch);
    }
  }

  // Setzen von Szenarien, Order, aktive IDs. Wenn profile nichts setzt, wird einfach wie vorher verfahren.
  store.setState({
    scenariosById: updates,
    scenarioOrder: scenarioOrder,
    selectedScenarioId: resp.profile?.selectedScenarioId || scenarioOrder[0],
    comparisonScenarioId: resp.profile?.comparisonScenarioId || (resp.scenarios[1]?.id ?? null)
  });

  await replacePlaceholder('‚úÖ Simulation eingerichtet! Ergebnisse werden berechnet.');
}


async function replacePlaceholder(text, chips = []) {
  const chat = getChat();
  chat.removeLastBotMessageIf('Nachdenken');          // drop the spinner bubble
  await chat.sendBot(text, chips);                    // show final answer
  // also keep the orchestrator‚Äôs convo in sync:
  const helper = getHelper();
  const convo  = helper.chats[chat._id];
  convo.messages.push({ role: 'bot', text });
  persistChats(helper.chats, chat._id);
}
